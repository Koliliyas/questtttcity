#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á –∏–∑ –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π TASKS.md –∏ COMPLETED_TASKS.md

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python3 scripts/sync_tasks.py
    python3 scripts/sync_tasks.py --dry-run
    python3 scripts/sync_tasks.py --verbose
    python3 scripts/sync_tasks.py --update-dates
"""

import os
import re
import argparse
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Set, Tuple
from dataclasses import dataclass
from enum import Enum


class Priority(Enum):
    CRITICAL = "üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
    HIGH = "üü° –í—ã—Å–æ–∫–∏–π" 
    MEDIUM = "üü¢ –°—Ä–µ–¥–Ω–∏–π"
    LOW = "üîµ –ù–∏–∑–∫–∏–π"


class Status(Enum):
    COMPLETED = "‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ"
    PLANNED = "‚è≥ –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ"
    IN_PROGRESS = "üîÑ –í –ø—Ä–æ—Ü–µ—Å—Å–µ"
    CANCELLED = "‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ"


@dataclass
class Task:
    id: str
    title: str
    status: Status
    priority: Priority
    date: str
    source: str
    description: str
    details: str = ""
    command: str = ""
    section: str = ""
    
    def __hash__(self):
        return hash(self.id)


class TaskManager:
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.docs_path = self.base_path / "docs"
        self.tasks_file = self.base_path / "TASKS.md"
        self.completed_file = self.base_path / "COMPLETED_TASKS.md"
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∏—Å–∫–∞
        self.completed_patterns = [
            r"‚úÖ\s*\*\*(.*?)\*\*\s*[-‚Äì‚Äî]\s*(.*)",
            r"‚úÖ\s*(.*?)\s*[-‚Äì‚Äî]\s*(.*)",
            r"\|\s*\*\*(.*?)\*\*\s*\|\s*‚úÖ\s*\|\s*(.*?)\s*\|",
            r"###\s*‚úÖ\s*(.*)",
            r"####\s*‚úÖ\s*(.*)",
        ]
        
        self.planned_patterns = [
            r"[-‚Äì‚Äî*]\s*\*\*(.*?)\*\*\s*[-‚Äì‚Äî]\s*(.*)",
            r"[-‚Äì‚Äî*]\s*(.*?)\s*[-‚Äì‚Äî]\s*(.*)",
            r"\d+\.\s*(.*?)\s*[-‚Äì‚Äî]\s*(.*)",
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏
        self.priority_keywords = {
            Priority.CRITICAL: ["–∫—Ä–∏—Ç–∏—á", "–±–ª–æ–∫–µ—Ä", "production", "urgent", "security", "connection pool", "grafana"],
            Priority.HIGH: ["–≤–∞–∂–Ω", "high", "performance", "optimization", "stripe", "—é–∫–∞—Å—Å–∞", "admin", "fcm"],
            Priority.MEDIUM: ["—Ä–µ–∫–æ–º–µ–Ω–¥", "improve", "enhance", "medium", "ci/cd", "google maps", "multi-tenant"],
            Priority.LOW: ["kubernetes", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", "analytics", "low"]
        }

    def update_dates_in_documents(self, target_date: str = "27 –∏—é–ª—è 2025"):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —Å —è–Ω–≤–∞—Ä—è –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –¥–∞—Ç—É"""
        print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞—Ç –Ω–∞ {target_date}...")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç –¥–ª—è –∑–∞–º–µ–Ω—ã
        date_patterns = [
            (r"(\d{1,2})\s+—è–Ω–≤–∞—Ä—è\s+2025", rf"27 –∏—é–ª—è 2025"),
            (r"27\s+January\s+2025", rf"27 July 2025"),
            (r"—è–Ω–≤–∞—Ä[—å—è]\s+2025", rf"–∏—é–ª—è 2025"),
            (r"January\s+2025", rf"July 2025"),
        ]
        
        files_to_update = [
            self.tasks_file,
            self.completed_file,
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ø–∞–ø–∫–∏ docs
        if self.docs_path.exists():
            for doc_file in self.docs_path.glob("*.md"):
                files_to_update.append(doc_file)
        
        updated_count = 0
        for file_path in files_to_update:
            if not file_path.exists():
                continue
                
            content = file_path.read_text(encoding='utf-8')
            original_content = content
            
            for pattern, replacement in date_patterns:
                content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
            
            if content != original_content:
                file_path.write_text(content, encoding='utf-8')
                updated_count += 1
                print(f"   üìÑ –û–±–Ω–æ–≤–ª–µ–Ω: {file_path.name}")
        
        print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {updated_count}")

    def determine_priority(self, text: str) -> Priority:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        text_lower = text.lower()
        
        for priority, keywords in self.priority_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                return priority
        
        return Priority.LOW

    def parse_completed_tasks_from_reports(self) -> List[Task]:
        """–ü–∞—Ä—Å–∏—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Ç—á–µ—Ç–æ–≤"""
        completed_tasks = []
        
        if not self.docs_path.exists():
            return completed_tasks
        
        report_files = list(self.docs_path.glob("*_REPORT.md")) + \
                      list(self.docs_path.glob("*_ANALYSIS.md")) + \
                      list(self.docs_path.glob("*_VERIFICATION.md")) + \
                      list(self.docs_path.glob("*_SYSTEM.md"))
        
        for file_path in report_files:
            try:
                content = file_path.read_text(encoding='utf-8')
                tasks = self._extract_completed_tasks_from_content(content, file_path.name)
                completed_tasks.extend(tasks)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
        
        return completed_tasks

    def _extract_completed_tasks_from_content(self, content: str, source: str) -> List[Task]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞"""
        tasks = []
        
        for pattern in self.completed_patterns:
            matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                title = match.group(1).strip()
                description = match.group(2).strip() if len(match.groups()) > 1 else ""
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–¥–∞—á–∏
                if len(title) < 10 or title.startswith("#"):
                    continue
                
                task = Task(
                    id=f"completed_{len(tasks)}_{source}",
                    title=title,
                    status=Status.COMPLETED,
                    priority=self.determine_priority(f"{title} {description}"),
                    date="27 –∏—é–ª—è 2025",
                    source=source,
                    description=description,
                    section=self._determine_section(title, description)
                )
                tasks.append(task)
        
        return tasks

    def parse_planned_tasks_from_reports(self) -> List[Task]:
        """–ü–∞—Ä—Å–∏—Ç –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Ç—á–µ—Ç–æ–≤"""
        planned_tasks = []
        
        if not self.docs_path.exists():
            return planned_tasks
        
        # –ò—â–µ–º –≤ roadmap –∏ future –ø–ª–∞–Ω–∞—Ö
        roadmap_files = [
            self.docs_path / "17_FUTURE_ROADMAP_REPORT.md",
            self.docs_path / "02_PROJECT_ROADMAP.md"
        ]
        
        for file_path in roadmap_files:
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8')
                    tasks = self._extract_planned_tasks_from_content(content, file_path.name)
                    planned_tasks.extend(tasks)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
        
        return planned_tasks

    def _extract_planned_tasks_from_content(self, content: str, source: str) -> List[Task]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞"""
        tasks = []
        
        # –ò—â–µ–º —Å–µ–∫—Ü–∏–∏ —Å –ø–ª–∞–Ω–∞–º–∏
        sections = re.split(r'##\s+', content)
        
        for section in sections:
            if any(keyword in section.lower() for keyword in ['—Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏', '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏', '–ø–ª–∞–Ω—ã']):
                for pattern in self.planned_patterns:
                    matches = re.finditer(pattern, section, re.MULTILINE)
                    for match in matches:
                        title = match.group(1).strip()
                        description = match.group(2).strip() if len(match.groups()) > 1 else ""
                        
                        if len(title) < 10:
                            continue
                        
                        task = Task(
                            id=f"planned_{len(tasks)}_{source}",
                            title=title,
                            status=Status.PLANNED,
                            priority=self.determine_priority(f"{title} {description}"),
                            date="27 –∏—é–ª—è 2025",
                            source=source,
                            description=description,
                            section=self._determine_section(title, description)
                        )
                        tasks.append(task)
        
        return tasks

    def _determine_section(self, title: str, description: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–¥–µ–ª –∑–∞–¥–∞—á–∏"""
        text = f"{title} {description}".lower()
        
        if any(word in text for word in ['–±–µ–∑–æ–ø–∞—Å–Ω', 'security', '—É—è–∑–≤–∏–º']):
            return "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å"
        elif any(word in text for word in ['–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω', 'performance', '–æ–ø—Ç–∏–º–∏–∑']):
            return "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
        elif any(word in text for word in ['–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥', 'logging', 'grafana']):
            return "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"
        elif any(word in text for word in ['–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü', 'ci/cd', 'deployment']):
            return "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è"
        elif any(word in text for word in ['–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä', '–º–æ–¥—É–ª—å', '—Å—Ç—Ä—É–∫—Ç—É—Ä']):
            return "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞"
        elif any(word in text for word in ['–ø–ª–∞—Ç–µ–∂', 'stripe', '—é–∫–∞—Å—Å–∞']):
            return "–ü–ª–∞—Ç–µ–∂–∏"
        else:
            return "–†–∞–∑–Ω–æ–µ"

    def sync_tasks(self, dry_run: bool = False, verbose: bool = False) -> Dict[str, int]:
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞—á"""
        if verbose:
            print("üîÑ –ù–∞—á–∏–Ω–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –∑–∞–¥–∞—á...")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
        completed_tasks = self.parse_completed_tasks_from_reports()
        planned_tasks = self.parse_planned_tasks_from_reports()
        
        stats = {
            'completed_found': len(completed_tasks),
            'planned_found': len(planned_tasks),
            'files_updated': 0
        }
        
        if verbose:
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ: {len(completed_tasks)} –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö, {len(planned_tasks)} –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª—ã (–µ—Å–ª–∏ –Ω–µ dry_run)
        if not dry_run:
            if completed_tasks:
                self._update_completed_tasks_file(completed_tasks)
                stats['files_updated'] += 1
            
            if planned_tasks:
                self._update_tasks_file(planned_tasks)
                stats['files_updated'] += 1
        
        return stats

    def _update_completed_tasks_file(self, tasks: List[Task]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–∞–π–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á"""
        # –§–∞–π–ª —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω –≤—Ä—É—á–Ω—É—é, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        pass

    def _update_tasks_file(self, tasks: List[Task]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–∞–π–ª –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á"""
        # –§–∞–π–ª —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω –≤—Ä—É—á–Ω—É—é, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        pass


def main():
    parser = argparse.ArgumentParser(description='–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á QuestCity Backend')
    parser.add_argument('--dry-run', action='store_true', 
                       help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è, –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞')
    parser.add_argument('--base-path', default='.',
                       help='–ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –ø—Ä–æ–µ–∫—Ç–∞')
    parser.add_argument('--update-dates', action='store_true',
                       help='–û–±–Ω–æ–≤–∏—Ç—å –¥–∞—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö')
    
    args = parser.parse_args()
    
    try:
        manager = TaskManager(args.base_path)
        
        if args.update_dates:
            manager.update_dates_in_documents()
            return
        
        stats = manager.sync_tasks(args.dry_run, args.verbose)
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:")
        print(f"   üÜï –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –Ω–∞–π–¥–µ–Ω–æ: {stats['completed_found']}")
        print(f"   üìã –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –Ω–∞–π–¥–µ–Ω–æ: {stats['planned_found']}")
        print(f"   üìÑ –§–∞–π–ª–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['files_updated']}")
        
        if args.dry_run:
            print("\n‚ö†Ô∏è –†–µ–∂–∏–º dry-run: –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        else:
            print("\n‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main()) 